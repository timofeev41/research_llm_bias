# Методология расчёта метрик Bias Analysis

## Обзор

Данный документ описывает методологию расчёта метрик для выявления смещения (bias) и неосмысленного оценивания в результатах пользовательского опроса по качеству ответов LLM.

---

## 1. Model Bias (Смещение к модели)

### Описание
Показывает, какой средний балл получает каждая модель от конкретного респондента.

### Формула расчёта

```
model_bias[model] = mean(scores[model])
```

Где:
- Для каждого ranking-вопроса позиция модели конвертируется в баллы:
  - 1-е место → 4 балла
  - 2-е место → 3 балла
  - 3-е место → 2 балла
  - 4-е место → 1 балл

### Интерпретация
| Значение | Интерпретация |
|----------|---------------|
| 2.5 | Нейтральное отношение (ожидаемое среднее) |
| > 3.0 | Сильное предпочтение модели |
| < 2.0 | Модель систематически занижается |

### Дополнительные метрики
- **model_bias_std**: Стандартное отклонение средних баллов между моделями
- **preference_gap**: Разница между лучшей и худшей моделью
- **preferred_model**: Модель с максимальным средним баллом
- **least_preferred_model**: Модель с минимальным средним баллом

---

## 2. Monotonicity Score (Паттерн монотонности)

### Описание
Проверяет, не ставит ли респондент оценки механически в одном и том же порядке.

### Формула расчёта

```python
for i in range(n_questions - 1):
    positions1 = [ranking1.index(model) for model in MODELS]
    positions2 = [ranking2.index(model) for model in MODELS]
    correlation = spearman_correlation(positions1, positions2)

monotonicity_score = mean(correlations)
```

### Алгоритм
1. Для каждой пары последовательных вопросов (Q_n, Q_{n+1})
2. Извлекаем позиции всех 4 моделей в обоих ранжированиях
3. Вычисляем коэффициент корреляции Спирмена между позициями
4. Усредняем корреляции по всем парам вопросов

### Интерпретация
| Значение | Интерпретация |
|----------|---------------|
| ~1.0 | Модели всегда в одинаковом порядке (механическое заполнение) |
| ~0.0 | Порядок случайный (нет паттерна) |
| ~-1.0 | Порядок всегда обратный |
| > 0.7 | **Флаг**: подозрение на механический паттерн |

---

## 3. Variance Score (Дисперсия оценок) - !!!!! НЕ СЧИТАЕМ ЕЕ! !!!!! ПОЛУЧИЛОСЬ ГОВНО

### Описание
Дисперсия всех выставленных баллов.

### Формула расчёта

```python
all_scores = []
for question in ranking_questions:
    for model in MODELS:
        score = rank_to_score(ranking, model)  # 4, 3, 2, 1
        all_scores.append(score)

variance_score = var(all_scores)
```

```
var([1, 2, 3, 4]) = 1.25
```

Метрика информативна только для оценок по шкале (например, 1-5 баллов), где возможны повторяющиеся значения.

---

## 4. Verbosity Bias (Предпочтение длины ответа)

### Описание
Показывает, предпочитает ли респондент более длинные или короткие ответы моделей.

### Формула расчёта

#### Шаг 1: Извлечение длин текстов
Из формы извлекаются тексты ответов каждой модели и вычисляется их длина в символах.

#### Шаг 2: Присвоение verbosity scores
Модели сортируются по длине и получают баллы по равномерной шкале:

```python
sorted_models = sort_by_length(models)  # от короткого к длинному
n = 4  # количество моделей

for i, model in enumerate(sorted_models):
    verbosity_score[model] = i / (n - 1)
```

| Позиция по длине | Verbosity Score |
|------------------|-----------------|
| Самый короткий | 0.000 |
| 2-й по длине | 0.333 |
| 3-й по длине | 0.667 |
| Самый длинный | 1.000 |

#### Шаг 3: Расчёт метрик

**verbosity_first** — средний verbosity score модели на 1-м месте:
```python
verbosity_first = mean([verbosity_score[ranking[0]] for ranking in questions])
```

**verbosity_weighted** — взвешенный verbosity с учётом всех позиций:
```python
weights = [4, 3, 2, 1]  # веса для позиций 1-4
for ranking in questions:
    weighted = sum(verbosity_score[model] * weight for model, weight in zip(ranking, weights))
    weighted /= sum(weights)
verbosity_weighted = mean(weighted_scores)
```

**verbosity_correlation** — корреляция Спирмена между длиной ответа и рангом:
```python
# Собираем все пары (длина, ранг)
lengths = [length[model] for all questions and models]
ranks = [position for all questions and models]

# Инвертируем знак: положительное значение = предпочитает длинные
verbosity_correlation = -spearman_correlation(lengths, ranks)
```

### Интерпретация

| Метрика | Значение | Интерпретация |
|---------|----------|---------------|
| verbosity_weighted | ~0.5 | Нейтральное отношение к длине |
| verbosity_weighted | > 0.7 | Предпочитает длинные ответы |
| verbosity_weighted | < 0.3 | Предпочитает короткие ответы |
| verbosity_correlation | > 0.3 | Значимая корреляция: длинные = лучше |
| verbosity_correlation | < -0.3 | Значимая корреляция: короткие = лучше |

---

## 5. Sanity Check (Проверка внимательности)

### Описание
В опросе есть 2 контрольных вопроса с очевидными правильными ответами.

### Правильные ответы
- **sanity_check_1**: "3" (Солнце встаёт на востоке)
- **sanity_check_2**: "2" (Вода замерзает при 0°C)

### Метрики
- **sanity_check_1_passed**: True/False
- **sanity_check_2_passed**: True/False
- **sanity_checks_passed**: True только если оба пройдены

### Интерпретация
Провал sanity check указывает на невнимательное заполнение опроса.

---

## Флаги подозрительных респондентов

| Флаг | Условие | Значение |
|------|---------|----------|
| flag_mechanical_pattern | monotonicity_score > 0.7 | Механическое заполнение |
| flag_low_variance | variance_score < 1.0 | Нет различий в оценках |
| flag_strong_model_bias | preference_gap > 1.5 | Сильное смещение к модели |
| flag_failed_sanity | sanity_checks_passed = False | Невнимательность |
| flag_verbosity_long | verbosity_weighted > 0.7 | Bias к длинным ответам |
| flag_verbosity_short | verbosity_weighted < 0.3 | Bias к коротким ответам |
| **suspicious** | Любой из критических флагов | Общий флаг подозрительности |

---

## Модели в исследовании

| ID модели | Цветовое название в форме |
|-----------|---------------------------|
| gemini-2.5-pro | Blue Whale / Red Panda / и др. (рандомизировано) |
| gemini-2.5-flash | — |
| DeepSeek-R1-0528 | — |
| Qwen3-235B-A22B-2507 | — |

> Примечание: Цветовые названия (животные) рандомизируются для каждого вопроса, чтобы избежать position bias.
